package ingest

import (
	"context"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strconv"
	"strings"

	"golearning/internal/content"
)

// MarkdownImporter –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —É—Ä–æ–∫–∏ –∏–∑ Markdown —Ñ–∞–π–ª–æ–≤.
type MarkdownImporter struct {
	repo    *content.Repository
	baseDir string
}

// NewMarkdownImporter —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π –∏–º–ø–æ—Ä—Ç—ë—Ä.
func NewMarkdownImporter(repo *content.Repository, baseDir string) *MarkdownImporter {
	return &MarkdownImporter{
		repo:    repo,
		baseDir: baseDir,
	}
}

// Import –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —É—Ä–æ–∫–∏ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
func (m *MarkdownImporter) Import(ctx context.Context) error {
	log.Printf("–ò–º–ø–æ—Ä—Ç —É—Ä–æ–∫–æ–≤ –∏–∑: %s", m.baseDir)

	// –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ (–≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å)
	guides, err := m.findGuides()
	if err != nil {
		return fmt.Errorf("find guides: %w", err)
	}

	// –ò–∫–æ–Ω–∫–∏ –¥–ª—è –∫—É—Ä—Å–æ–≤
	courseIcons := map[int]string{
		1: "üìò", // –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —è–∑—ã–∫—É Go
		2: "üåê", // –í–µ–±-–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
		3: "üöÄ", // –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
	}

	moduleIndex := 0
	for _, guide := range guides {
		log.Printf("üìö –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ: %s", guide.Title)

		// –°–æ–∑–¥–∞—ë–º –∫—É—Ä—Å –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
		icon := courseIcons[guide.Order]
		if icon == "" {
			icon = "üìö"
		}
		course := &content.Course{
			Slug:        m.slugify(guide.Title),
			Title:       guide.Title,
			Description: "",
			Icon:        icon,
			OrderIndex:  guide.Order,
		}

		if err := m.repo.CreateCourse(course); err != nil {
			log.Printf("  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫—É—Ä—Å–∞: %v", err)
			continue
		}
		log.Printf("  üìö –ö—É—Ä—Å: %s (ID=%d)", course.Title, course.ID)

		// –ù–∞—Ö–æ–¥–∏–º –≥–ª–∞–≤—ã –≤–Ω—É—Ç—Ä–∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
		chapters, err := m.findChapters(guide.Path)
		if err != nil {
			log.Printf("  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≥–ª–∞–≤: %v", err)
			continue
		}

		for _, chapter := range chapters {
			// –°–æ–∑–¥–∞—ë–º –º–æ–¥—É–ª—å –¥–ª—è –≥–ª–∞–≤—ã
			module := &content.Module{
				CourseID:   course.ID,
				Slug:       m.slugify(chapter.Title),
				Title:      chapter.Title,
				OrderIndex: moduleIndex,
			}

			if err := m.repo.CreateModule(module); err != nil {
				log.Printf("  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥—É–ª—è: %v", err)
				continue
			}
			log.Printf("  üìÅ –ú–æ–¥—É–ª—å: %s (ID=%d)", module.Title, module.ID)
			moduleIndex++

			// –ù–∞—Ö–æ–¥–∏–º –∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É—Ä–æ–∫–∏
			lessons, err := m.findLessons(chapter.Path)
			if err != nil {
				log.Printf("    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —É—Ä–æ–∫–æ–≤: %v", err)
				continue
			}

			for _, lessonFile := range lessons {
				if err := m.importLesson(ctx, module.ID, lessonFile); err != nil {
					log.Printf("    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —É—Ä–æ–∫–∞ %s: %v", lessonFile.Name, err)
				}
			}
		}
	}

	return nil
}

// DirEntry –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏–ª–∏ —Ñ–∞–π–ª.
type DirEntry struct {
	Name  string
	Title string
	Path  string
	Order int
}

// findGuides –Ω–∞—Ö–æ–¥–∏—Ç —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ (–≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π).
func (m *MarkdownImporter) findGuides() ([]DirEntry, error) {
	entries, err := os.ReadDir(m.baseDir)
	if err != nil {
		return nil, err
	}

	var guides []DirEntry
	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		name := entry.Name()
		// –°–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ‚Äî –Ω–µ —Å—á–∏—Ç–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –∫—É—Ä—Å–∞–º–∏.
		// –ù–∞–ø—Ä–∏–º–µ—Ä, lessons_mdx/–ü—Ä–æ–µ–∫—Ç—ã —Å–æ–¥–µ—Ä–∂–∏—Ç –¢–ó capstone-–ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã /projects.
		if name == "–ü—Ä–æ–µ–∫—Ç—ã" || strings.HasPrefix(name, ".") || strings.HasPrefix(name, "_") {
			continue
		}
		order, title := m.parseNumberedName(name)

		guides = append(guides, DirEntry{
			Name:  name,
			Title: title,
			Path:  filepath.Join(m.baseDir, name),
			Order: order,
		})
	}

	sort.Slice(guides, func(i, j int) bool {
		return guides[i].Order < guides[j].Order
	})

	return guides, nil
}

// findChapters –Ω–∞—Ö–æ–¥–∏—Ç –≥–ª–∞–≤—ã –≤–Ω—É—Ç—Ä–∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.
func (m *MarkdownImporter) findChapters(guidePath string) ([]DirEntry, error) {
	entries, err := os.ReadDir(guidePath)
	if err != nil {
		return nil, err
	}

	var chapters []DirEntry
	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		name := entry.Name()
		order, title := m.parseNumberedName(name)

		chapters = append(chapters, DirEntry{
			Name:  name,
			Title: title,
			Path:  filepath.Join(guidePath, name),
			Order: order,
		})
	}

	sort.Slice(chapters, func(i, j int) bool {
		return chapters[i].Order < chapters[j].Order
	})

	return chapters, nil
}

// findLessons –Ω–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã —É—Ä–æ–∫–æ–≤ –≤ –≥–ª–∞–≤–µ.
func (m *MarkdownImporter) findLessons(chapterPath string) ([]DirEntry, error) {
	entries, err := os.ReadDir(chapterPath)
	if err != nil {
		return nil, err
	}

	var lessons []DirEntry
	for _, entry := range entries {
		if entry.IsDir() || !strings.HasSuffix(entry.Name(), ".md") {
			continue
		}

		name := entry.Name()
		order, title := m.parseNumberedName(strings.TrimSuffix(name, ".md"))

		lessons = append(lessons, DirEntry{
			Name:  name,
			Title: title,
			Path:  filepath.Join(chapterPath, name),
			Order: order,
		})
	}

	sort.Slice(lessons, func(i, j int) bool {
		return lessons[i].Order < lessons[j].Order
	})

	return lessons, nil
}

// parseNumberedName –ø–∞—Ä—Å–∏—Ç –∏–º—è –≤–∏–¥–∞ "01_–ù–∞–∑–≤–∞–Ω–∏–µ_—Ç–µ–º—ã" -> (1, "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
func (m *MarkdownImporter) parseNumberedName(name string) (int, string) {
	// –ü–∞—Ç—Ç–µ—Ä–Ω: "01_..." –∏–ª–∏ "–ì–ª–∞–≤–∞_01_..."
	re := regexp.MustCompile(`^(\d+)_(.+)$`)
	if matches := re.FindStringSubmatch(name); len(matches) == 3 {
		order, _ := strconv.Atoi(matches[1])
		title := strings.ReplaceAll(matches[2], "_", " ")
		return order, title
	}

	// –ü–∞—Ç—Ç–µ—Ä–Ω: "–ì–ª–∞–≤–∞_01_..."
	re2 := regexp.MustCompile(`^–ì–ª–∞–≤–∞_(\d+)_(.+)$`)
	if matches := re2.FindStringSubmatch(name); len(matches) == 3 {
		order, _ := strconv.Atoi(matches[1])
		title := strings.ReplaceAll(matches[2], "_", " ")
		return order, title
	}

	// –ë–µ–∑ –Ω–æ–º–µ—Ä–∞
	title := strings.ReplaceAll(name, "_", " ")
	return 0, title
}

// importLesson –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —É—Ä–æ–∫ –∏–∑ Markdown —Ñ–∞–π–ª–∞.
func (m *MarkdownImporter) importLesson(ctx context.Context, moduleID int64, lessonFile DirEntry) error {
	// –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
	data, err := os.ReadFile(lessonFile.Path)
	if err != nil {
		return fmt.Errorf("read file: %w", err)
	}

	mdContent := string(data)

	// –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
	title := lessonFile.Title
	if h1 := m.extractH1(mdContent); h1 != "" {
		title = h1
	}

	// –°–æ–∑–¥–∞—ë–º slug
	slug := m.slugify(title) + "-" + strconv.Itoa(lessonFile.Order)

	// –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤—Ä–µ–º—è —á—Ç–µ–Ω–∏—è (–ø—Ä–∏–º–µ—Ä–Ω–æ 200 —Å–ª–æ–≤ –≤ –º–∏–Ω—É—Ç—É)
	wordCount := len(strings.Fields(mdContent))
	readingTime := wordCount / 200
	if readingTime < 5 {
		readingTime = 5
	}

	// –°–æ–∑–¥–∞—ë–º —É—Ä–æ–∫
	lesson := &content.Lesson{
		ModuleID:       moduleID,
		Slug:           slug,
		Title:          title,
		OrderIndex:     lessonFile.Order,
		SourceURL:      "",
		BodyMD:         mdContent,
		ReadingTimeMin: readingTime,
	}

	if err := m.repo.CreateLesson(lesson); err != nil {
		return fmt.Errorf("create lesson: %w", err)
	}
	log.Printf("    üìÑ –£—Ä–æ–∫: %s (ID=%d, ~%d –º–∏–Ω)", title, lesson.ID, readingTime)

	// –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–µ–∫—Ü–∏–∏ –∏ –∑–∞–¥–∞–Ω–∏—è
	m.repo.DeleteSectionsByLessonID(lesson.ID)
	m.repo.DeleteTasksByLessonID(lesson.ID)

	// –ü–∞—Ä—Å–∏–º –∏ —Å–æ–∑–¥–∞—ë–º —Å–µ–∫—Ü–∏–∏
	sections := m.parseSections(mdContent)
	for i, sec := range sections {
		section := &content.Section{
			LessonID:   lesson.ID,
			Kind:       sec.Kind,
			Title:      sec.Title,
			BodyMD:     sec.Body,
			OrderIndex: i,
		}
		if err := m.repo.CreateSection(section); err != nil {
			log.Printf("      ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ–∫—Ü–∏–∏: %v", err)
		}
	}

	// –ü–∞—Ä—Å–∏–º –∏ —Å–æ–∑–¥–∞—ë–º –∑–∞–¥–∞–Ω–∏—è
	tasks := m.parseTasks(mdContent)
	for i, task := range tasks {
		t := &content.Task{
			LessonID:         lesson.ID,
			Title:            task.Title,
			PromptMD:         task.Prompt,
			StarterCode:      task.StarterCode,
			TestsGo:          task.Tests,
			ExpectedOutput:   task.ExpectedOutput,
			RequiredPatterns: task.RequiredPatterns,
			Points:           task.Points,
			OrderIndex:       i,
		}
		if err := m.repo.CreateTask(t); err != nil {
			log.Printf("      ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è: %v", err)
		}
	}

	if len(tasks) > 0 {
		log.Printf("      ‚úÖ %d –∑–∞–¥–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–æ", len(tasks))
	}

	return nil
}

// ParsedSection –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—É—é —Å–µ–∫—Ü–∏—é.
type ParsedSection struct {
	Kind  content.SectionKind
	Title string
	Body  string
}

// parseSections –ø–∞—Ä—Å–∏—Ç —Å–µ–∫—Ü–∏–∏ –∏–∑ Markdown.
func (m *MarkdownImporter) parseSections(md string) []ParsedSection {
	var sections []ParsedSection

	// –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è
	re := regexp.MustCompile(`(?m)^## (.+)$`)
	matches := re.FindAllStringSubmatchIndex(md, -1)

	for i, match := range matches {
		titleStart, titleEnd := match[2], match[3]
		title := md[titleStart:titleEnd]

		// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Å–µ–∫—Ü–∏–∏
		bodyStart := match[1]
		var bodyEnd int
		if i+1 < len(matches) {
			bodyEnd = matches[i+1][0]
		} else {
			bodyEnd = len(md)
		}

		body := strings.TrimSpace(md[bodyStart:bodyEnd])

		// –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ body
		body = strings.TrimPrefix(body, "## "+title)
		body = strings.TrimSpace(body)

		// –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–µ–∫—Ü–∏–∏ –ø–æ —ç–º–æ–¥–∑–∏ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—é
		kind := m.detectSectionKind(title)

		// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–∫—Ü–∏–∏ "–ü—Ä–∞–∫—Ç–∏–∫–∞" –∏ "–ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏" ‚Äî –æ–Ω–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
		if kind == "practice" || strings.Contains(strings.ToLower(title), "–ø–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏") {
			continue
		}

		// –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
		cleanTitle := m.cleanSectionTitle(title)

		sections = append(sections, ParsedSection{
			Kind:  kind,
			Title: cleanTitle,
			Body:  body,
		})
	}

	return sections
}

// detectSectionKind –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å–µ–∫—Ü–∏–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É.
func (m *MarkdownImporter) detectSectionKind(title string) content.SectionKind {
	lower := strings.ToLower(title)

	switch {
	case strings.Contains(title, "üí°") || strings.Contains(lower, "–∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏"):
		return content.SectionOverview
	case strings.Contains(title, "üìã") || strings.Contains(lower, "—Å–∏–Ω—Ç–∞–∫—Å–∏—Å"):
		return content.SectionSyntax
	case strings.Contains(title, "üíª") || strings.Contains(lower, "–ø—Ä–∏–º–µ—Ä"):
		return content.SectionExamples
	case strings.Contains(title, "‚ö†Ô∏è") || strings.Contains(lower, "–æ—à–∏–±–∫"):
		return content.SectionPitfalls
	case strings.Contains(title, "üìù") || strings.Contains(title, "üèãÔ∏è") || strings.Contains(lower, "–ø—Ä–∞–∫—Ç–∏–∫–∞") || strings.Contains(lower, "–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è"):
		return "practice"
	default:
		return content.SectionExtra
	}
}

// cleanSectionTitle —É–±–∏—Ä–∞–µ—Ç —ç–º–æ–¥–∑–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å–µ–∫—Ü–∏–∏.
func (m *MarkdownImporter) cleanSectionTitle(title string) string {
	// –£–±–∏—Ä–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —ç–º–æ–¥–∑–∏
	emojis := []string{"üí°", "üìã", "üíª", "‚ö†Ô∏è", "üìù", "üîó", "üìö", "üèãÔ∏è", "üìñ"}
	result := title
	for _, emoji := range emojis {
		result = strings.ReplaceAll(result, emoji, "")
	}
	return strings.TrimSpace(result)
}

// ParsedTask –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ.
type ParsedTask struct {
	Title            string
	Prompt           string
	StarterCode      string
	Tests            string
	ExpectedOutput   string
	RequiredPatterns string
	Points           int
}

// parseTasks –ø–∞—Ä—Å–∏—Ç –∑–∞–¥–∞–Ω–∏—è –∏–∑ —Å–µ–∫—Ü–∏–∏ "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è".
func (m *MarkdownImporter) parseTasks(md string) []ParsedTask {
	var tasks []ParsedTask

	// –ù–∞—Ö–æ–¥–∏–º —Å–µ–∫—Ü–∏—é "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è" ‚Äî –∏—â–µ–º –æ—Ç ## üèãÔ∏è –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ ## –∏–ª–∏ –∫–æ–Ω—Ü–∞
	practiceStart := -1
	lines := strings.Split(md, "\n")
	for i, line := range lines {
		// –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞: —Å—Ç–∞—Ä—ã–π "–ü—Ä–∞–∫—Ç–∏–∫–∞" –∏ –Ω–æ–≤—ã–π "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è"
		if strings.HasPrefix(line, "## ") && (strings.Contains(line, "üèãÔ∏è") || strings.Contains(strings.ToLower(line), "–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è") || strings.Contains(strings.ToLower(line), "–ø—Ä–∞–∫—Ç–∏–∫–∞")) {
			practiceStart = i + 1
			break
		}
	}

	if practiceStart < 0 {
		return tasks
	}

	// –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü —Å–µ–∫—Ü–∏–∏ "–ü—Ä–∞–∫—Ç–∏–∫–∞"
	practiceEnd := len(lines)
	for i := practiceStart; i < len(lines); i++ {
		if strings.HasPrefix(lines[i], "## ") || strings.HasPrefix(lines[i], "---") {
			practiceEnd = i
			break
		}
	}

	practiceContent := strings.Join(lines[practiceStart:practiceEnd], "\n")

	// –ù–∞—Ö–æ–¥–∏–º –∑–∞–¥–∞–Ω–∏—è ‚Äî –∏—â–µ–º ### –ó–∞–¥–∞–Ω–∏–µ
	taskStarts := []int{}
	taskLines := strings.Split(practiceContent, "\n")
	for i, line := range taskLines {
		if strings.HasPrefix(line, "### ") && strings.Contains(strings.ToLower(line), "–∑–∞–¥–∞–Ω–∏–µ") {
			taskStarts = append(taskStarts, i)
		}
	}

	for idx, start := range taskStarts {
		// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü –∑–∞–¥–∞–Ω–∏—è
		var end int
		if idx+1 < len(taskStarts) {
			end = taskStarts[idx+1]
		} else {
			end = len(taskLines)
		}

		taskContent := strings.Join(taskLines[start:end], "\n")

		// –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
		titleLine := taskLines[start]
		title := strings.TrimPrefix(titleLine, "### ")
		title = strings.TrimSpace(title)

		// –ò—â–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥: **–ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥:** + –±–ª–æ–∫ –∫–æ–¥–∞
		starterCode := m.extractStarterCode(taskContent)

		// –ò—â–µ–º –æ–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥: **–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:** –∏–ª–∏ > –í—ã–≤–æ–¥:
		expectedOutput := m.extractExpectedOutput(taskContent)

		// –ò—â–µ–º —Ç—Ä–µ–±—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:** –∏–ª–∏ **–î–æ–ª–∂–Ω–æ –±—ã—Ç—å:**
		requiredPatterns := m.extractRequiredPatterns(taskContent)

		// –ò—â–µ–º –±–∞–ª–ª—ã: **–ë–∞–ª–ª—ã:** —á–∏—Å–ª–æ
		points := m.extractPoints(taskContent, idx)

		// –ò—â–µ–º —Ä–µ—à–µ–Ω–∏–µ –≤ <details> (–µ—Å–ª–∏ –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω)
		if starterCode == "" {
			solutionRe := regexp.MustCompile("(?s)<details>.*?```go\n(.+?)```.*?</details>")
			solutionMatch := solutionRe.FindStringSubmatch(taskContent)
			if len(solutionMatch) >= 2 {
				starterCode = m.generateStarterCode(strings.TrimSpace(solutionMatch[1]))
			}
		}

		// –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ—Ç ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π
		if starterCode == "" {
			starterCode = m.generateStarterCode("")
		}

		// –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –∫–æ–¥ –∏ –¥–µ—Ç–∞–ª–∏)
		prompt := m.extractPrompt(taskContent, title)

		tasks = append(tasks, ParsedTask{
			Title:            title,
			Prompt:           prompt,
			StarterCode:      starterCode,
			Tests:            "",
			ExpectedOutput:   expectedOutput,
			RequiredPatterns: requiredPatterns,
			Points:           points,
		})
	}

	return tasks
}

// generateStarterCode —Å–æ–∑–¥–∞—ë—Ç –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—à–µ–Ω–∏—è.
func (m *MarkdownImporter) generateStarterCode(solution string) string {
	if solution == "" {
		return `package main

import "fmt"

func main() {
	// –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –∫–æ–¥ –∑–¥–µ—Å—å
	
}
`
	}

	// –£–ø—Ä–æ—â–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —É–±–∏—Ä–∞–µ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é
	lines := strings.Split(solution, "\n")
	var result []string

	inFunc := false
	braceCount := 0

	for _, line := range lines {
		trimmed := strings.TrimSpace(line)

		// –°–æ—Ö—Ä–∞–Ω—è–µ–º package –∏ import
		if strings.HasPrefix(trimmed, "package") || strings.HasPrefix(trimmed, "import") {
			result = append(result, line)
			continue
		}

		// –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É package/import
		if trimmed == "" && !inFunc {
			result = append(result, line)
			continue
		}

		// –ù–∞—á–∞–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ main
		if strings.HasPrefix(trimmed, "func main()") {
			result = append(result, line)
			inFunc = true
			braceCount = 1
			result = append(result, "\t// –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –∫–æ–¥ –∑–¥–µ—Å—å")
			result = append(result, "\t")
			continue
		}

		// –í–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ ‚Äî —Å—á–∏—Ç–∞–µ–º —Å–∫–æ–±–∫–∏
		if inFunc {
			braceCount += strings.Count(line, "{") - strings.Count(line, "}")
			if braceCount <= 0 {
				result = append(result, "}")
				inFunc = false
			}
		}
	}

	return strings.Join(result, "\n")
}

// extractStarterCode –∏–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞–Ω–∏—è.
func (m *MarkdownImporter) extractStarterCode(taskContent string) string {
	// –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: **–ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥:** + –±–ª–æ–∫ –∫–æ–¥–∞
	patterns := []string{
		`(?s)\*\*–ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥[:\*]*\*\*\s*\n\s*` + "```go\n(.+?)```",
		`(?s)\*\*–ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥[:\*]*\*\*\s*\n\s*` + "```\n(.+?)```",
	}

	for _, pattern := range patterns {
		re := regexp.MustCompile(pattern)
		if match := re.FindStringSubmatch(taskContent); len(match) >= 2 {
			return strings.TrimSpace(match[1])
		}
	}

	return ""
}

// extractPoints –∏–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–ª–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞–Ω–∏—è.
func (m *MarkdownImporter) extractPoints(taskContent string, idx int) int {
	// –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: **–ë–∞–ª–ª—ã:** —á–∏—Å–ª–æ
	re := regexp.MustCompile(`\*\*–ë–∞–ª–ª—ã[:\*]*\*\*\s*(\d+)`)
	if match := re.FindStringSubmatch(taskContent); len(match) >= 2 {
		if points, err := strconv.Atoi(match[1]); err == nil {
			return points
		}
	}
	// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 10 + (idx * 5)
	return 10 + (idx * 5)
}

// extractPrompt –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è, —É–±–∏—Ä–∞—è –∫–æ–¥ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –±–ª–æ–∫–∏.
func (m *MarkdownImporter) extractPrompt(taskContent, title string) string {
	prompt := taskContent

	// –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
	prompt = strings.TrimPrefix(prompt, "### "+title)

	// –£–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞ (–Ω–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥, –æ–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥)
	codeBlockRe := regexp.MustCompile("(?s)```[^`]*```")
	prompt = codeBlockRe.ReplaceAllString(prompt, "")

	// –£–±–∏—Ä–∞–µ–º <details>
	detailsRe := regexp.MustCompile("(?s)<details>.*?</details>")
	prompt = detailsRe.ReplaceAllString(prompt, "")

	// –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
	linesToRemove := []string{
		`\*\*–ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–¥[:\*]*\*\*`,
		`\*\*–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥[:\*]*\*\*`,
		`\*\*–ë–∞–ª–ª—ã[:\*]*\*\*\s*\d+`,
	}
	for _, pattern := range linesToRemove {
		re := regexp.MustCompile(pattern)
		prompt = re.ReplaceAllString(prompt, "")
	}

	// –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥—Ä—è–¥
	for strings.Contains(prompt, "\n\n\n") {
		prompt = strings.ReplaceAll(prompt, "\n\n\n", "\n\n")
	}

	return strings.TrimSpace(prompt)
}

// extractExpectedOutput –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞–Ω–∏—è.
func (m *MarkdownImporter) extractExpectedOutput(taskContent string) string {
	// –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∏–¥–∞:
	// **–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
	// ```
	// Hello, World!
	// ```
	patterns := []string{
		`(?s)\*\*–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥[:\*]*\*\*\s*\n\s*` + "```" + `[^\n]*\n(.+?)` + "```",
		`(?s)>?\s*–í—ã–≤–æ–¥[:\s]*\n\s*` + "```" + `[^\n]*\n(.+?)` + "```",
		`(?s)\*\*–†–µ–∑—É–ª—å—Ç–∞—Ç[:\*]*\*\*\s*\n\s*` + "```" + `[^\n]*\n(.+?)` + "```",
	}

	for _, pattern := range patterns {
		re := regexp.MustCompile(pattern)
		if match := re.FindStringSubmatch(taskContent); len(match) >= 2 {
			return strings.TrimSpace(match[1])
		}
	}

	return ""
}

// extractRequiredPatterns –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç—Ä–µ–±—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞–Ω–∏—è.
func (m *MarkdownImporter) extractRequiredPatterns(taskContent string) string {
	// –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∏–¥–∞:
	// **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:** `for`, `if`
	// **–î–æ–ª–∂–Ω–æ –±—ã—Ç—å:** fmt.Println
	patterns := []string{
		`\*\*–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ[:\*]*\*\*\s*(.+)`,
		`\*\*–î–æ–ª–∂–Ω–æ –±—ã—Ç—å[:\*]*\*\*\s*(.+)`,
		`\*\*–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ[:\*]*\*\*\s*(.+)`,
	}

	var allPatterns []string
	for _, pattern := range patterns {
		re := regexp.MustCompile(pattern)
		if match := re.FindStringSubmatch(taskContent); len(match) >= 2 {
			// –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –∏–∑ backticks
			codeRe := regexp.MustCompile("`([^`]+)`")
			codes := codeRe.FindAllStringSubmatch(match[1], -1)
			for _, c := range codes {
				if len(c) >= 2 {
					allPatterns = append(allPatterns, c[1])
				}
			}
		}
	}

	return strings.Join(allPatterns, "|")
}

// computeExpectedOutput –≤—ã—á–∏—Å–ª—è–µ—Ç –æ–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ –∏–∑ —Ä–µ—à–µ–Ω–∏—è.
func (m *MarkdownImporter) computeExpectedOutput(solutionCode string) string {
	// –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥: –∏—â–µ–º fmt.Println("...") –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏
	re := regexp.MustCompile(`fmt\.Print(?:ln|f)?\s*\(\s*"([^"]*)"`)
	matches := re.FindAllStringSubmatch(solutionCode, -1)

	var outputs []string
	for _, match := range matches {
		if len(match) >= 2 {
			outputs = append(outputs, match[1])
		}
	}

	if len(outputs) > 0 {
		return strings.Join(outputs, "\n")
	}

	return ""
}

// generateTests —Å–æ–∑–¥–∞—ë—Ç –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –∑–∞–¥–∞–Ω–∏—è.
func (m *MarkdownImporter) generateTests(solution string, taskNum int) string {
	// –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–¥ –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç—Å—è –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
	return fmt.Sprintf(`package main

import (
	"bytes"
	"os/exec"
	"testing"
)

func TestTask%d(t *testing.T) {
	cmd := exec.Command("go", "run", "main.go")
	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	err := cmd.Run()
	if err != nil {
		t.Fatalf("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π:\n%%s\n%%s", stderr.String(), err)
	}

	output := stdout.String()
	if output == "" {
		t.Log("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ (–±–µ–∑ –≤—ã–≤–æ–¥–∞)")
	} else {
		t.Logf("–í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–∞–º–º—ã:\n%%s", output)
	}
}
`, taskNum)
}

// extractH1 –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è.
func (m *MarkdownImporter) extractH1(md string) string {
	re := regexp.MustCompile(`(?m)^# (.+)$`)
	if match := re.FindStringSubmatch(md); len(match) >= 2 {
		return strings.TrimSpace(match[1])
	}
	return ""
}

// slugify –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ slug.
func (m *MarkdownImporter) slugify(s string) string {
	// –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
	translit := map[rune]string{
		'–∞': "a", '–±': "b", '–≤': "v", '–≥': "g", '–¥': "d", '–µ': "e", '—ë': "yo",
		'–∂': "zh", '–∑': "z", '–∏': "i", '–π': "y", '–∫': "k", '–ª': "l", '–º': "m",
		'–Ω': "n", '–æ': "o", '–ø': "p", '—Ä': "r", '—Å': "s", '—Ç': "t", '—É': "u",
		'—Ñ': "f", '—Ö': "h", '—Ü': "ts", '—á': "ch", '—à': "sh", '—â': "sch",
		'—ä': "", '—ã': "y", '—å': "", '—ç': "e", '—é': "yu", '—è': "ya",
		'–ê': "a", '–ë': "b", '–í': "v", '–ì': "g", '–î': "d", '–ï': "e", '–Å': "yo",
		'–ñ': "zh", '–ó': "z", '–ò': "i", '–ô': "y", '–ö': "k", '–õ': "l", '–ú': "m",
		'–ù': "n", '–û': "o", '–ü': "p", '–†': "r", '–°': "s", '–¢': "t", '–£': "u",
		'–§': "f", '–•': "h", '–¶': "ts", '–ß': "ch", '–®': "sh", '–©': "sch",
		'–™': "", '–´': "y", '–¨': "", '–≠': "e", '–Æ': "yu", '–Ø': "ya",
	}

	var result strings.Builder
	for _, r := range s {
		if t, ok := translit[r]; ok {
			result.WriteString(t)
		} else if (r >= 'a' && r <= 'z') || (r >= 'A' && r <= 'Z') || (r >= '0' && r <= '9') {
			result.WriteRune(r)
		} else if r == ' ' || r == '-' || r == '_' {
			result.WriteRune('-')
		}
	}

	// –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ—Ñ–∏—Å—ã
	slug := result.String()
	for strings.Contains(slug, "--") {
		slug = strings.ReplaceAll(slug, "--", "-")
	}
	slug = strings.Trim(slug, "-")
	slug = strings.ToLower(slug)

	return slug
}
